{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1svrnByQUc-g"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Snlt3iiUc-r"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "from ipywidgets import interact\n",
        "\n",
        "ground_truth = lambda x: x * np.sin(x*2)\n",
        "def get_data(ground_truth, n_samples, noise=0.5):\n",
        "    X = np.random.uniform(0, 6, n_samples)\n",
        "    y = ground_truth(X) + np.random.randn(*X.shape)*noise\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k7MvlPvUc-t"
      },
      "source": [
        "# Gaussian Processes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTu_GfL-Uc-u"
      },
      "source": [
        "In this exercise, we will implement a Gaussian process for regession."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjsfIEuNUc-v"
      },
      "source": [
        "np.random.seed(5)\n",
        "X, y = get_data(ground_truth, n_samples=11)\n",
        "axis = np.linspace(0, 6, 101)\n",
        "\n",
        "plt.plot(axis, ground_truth(axis), label='Ground Truth')\n",
        "plt.scatter(X, y, label='Training Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X837eqpmUc-w"
      },
      "source": [
        "## Kernel functions\n",
        "Implement the kernel functions which are defined below.\n",
        "\n",
        "> Exponential Covariance (Equation 6.63): $$k(\\mathbf{x}_n, \\mathbf{x}_m)  = \\theta_0 \\exp\\left( - \\frac{\\theta_1}{2} \\Vert \\mathbf{x}_n - \\mathbf{x}_m \\Vert^2 \\right) + \\theta_2 + \\theta_3 \\mathbf{x}_n^T\\mathbf{x}_m.$$\n",
        "> Exponential Kernel (Equation 6.56): $$k\\left(x, x^{\\prime}\\right)=\\exp \\left(-\\theta\\left|x-x^{\\prime}\\right|\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x4FaaFyUc-x"
      },
      "source": [
        "class ExponentialCovariance:\n",
        "    \"\"\"Gaussian kernel from Eq. 6.63.\"\"\"\n",
        "    def __init__(self, theta0=1, theta1=1, theta2=0, theta3=0):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "kernel = ExponentialCovariance()\n",
        "kernel(2, 1) # should return 0.6065306597126334"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0a-fCkTUc-y"
      },
      "source": [
        "class ExponentialKernel:\n",
        "    \"\"\"Exponential kernel from Eq. 6.56.\"\"\"\n",
        "    def __init__(self, theta=1):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "kernel = ExponentialKernel()\n",
        "kernel(2, 1) # should return 0.36787944117144233"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK7fLZP0Uc-z"
      },
      "source": [
        "        Feel free to implement additional kernels from the lecture. They can be used in the resulting GP model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8L1SwwzUc-0"
      },
      "source": [
        "## Prior Distribution\n",
        "\n",
        "> Implment the class `GaussianProcess` with the following methods:\n",
        "> - `__init__`: Initializes all hyperparameters of our model. In this case we need the corresponding kernel function we want to use.\n",
        "> - `prior_samples`: Provides random samples from the prior distribution over functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogqlAQdNUc-1"
      },
      "source": [
        "class GaussianProcess:\n",
        "    def __init__(self, kernel_func):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def prior_samples(self, X, n_samples):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqceGLjQUc-3"
      },
      "source": [
        "> Plot samples according to the figure on slide 18."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcUbArFiUc-4"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8z9PdjwUc-4"
      },
      "source": [
        "## Conditional distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3HxpiqIUc-5"
      },
      "source": [
        "Our ultimate goal is to find the predictive distribution. That is, we seek to evaluate  $p(t_{N+1}| \\mathbf{t})$ for a new sample $\\mathbf{x}_{N+1}$.\n",
        "In order to find the conditional distribution $p(t_{N+1}| \\mathbf{t})$:\n",
        "1. We start by writing down the joint distribution $p(\\mathbf{t}_{N+1})$, where $\\mathbf{t}_{N+1}$ denotes the vector $(t_1,\\ldots,t_N, t_{N+1})^T$.\n",
        "2. We then apply the results from Section 2.3.1 to obtain the required conditional distribution.\n",
        "\n",
        "### Joint Distribution\n",
        "The joint distribution over $t_1, \\ldots, t_{N+1}$ will be given by $$\\quad p(\\mathbf{t}_{N+1}) = \\mathcal{N}(\\mathbf{t}_{N+1}| \\mathbf{0}, \\mathbf{C}_{n+1})$$\n",
        "where $\\mathbf{C}_{N+1}$ is an $(N+1)\\times(N+1)$ covariance matrix with elements given by $$\\quad C\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)=k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)+\\beta^{-1} \\delta_{n m}$$\n",
        "where $\\beta$ is a hyperparameter representing the precision of the noise.\n",
        "Because the joint distribution is Gaussian, we can apply the results from Section 2.3.1 to find the conditional Gaussian distribution. To do this, we partition the covariance matrix as follows\n",
        "$$\\quad \\textbf{C}_{N+1} =  \\left( \\begin{array}{cc} \\textbf{C}_{N} & \\textbf{k}  \\\\ \\textbf{k}^{T} & c  \\\\ \\end{array} \\right)$$ where $\\mathbf{C}_N$ is the $N \\times N$ covariance matrix, the vector $\\mathbf{k}$ has elements $k(\\mathbf{x}_n, \\mathbf{x}_{N+1})$ for $n = 1,\\ldots,N$, and the scalar $c = k(\\mathbf{x}_{N+1}, \\mathbf{x}_{N+1}) + \\beta^{-1}$. We see that the conditional distribution $p(t_{N+1}|\\mathbf{t})$ is a Gaussian distribution with mean and covariance given by\n",
        "$$\\quad m(\\mathbf{x}_{N+1}) = \\mathbf{k}^T \\mathbf{C}_N^{-1}\\mathbf{t} \\quad \\quad \\sigma^2 (\\mathbf{x}_{N+1}) =  c - \\mathbf{k}^T\\mathbf{C}_n^{-1}\\mathbf{k}$$\n",
        "\n",
        "The only restriction on the kernel function is that the covariance matrix must be positive definite. If $\\lambda_i$ is an eigenvalue of $\\mathbf{K}$, then the corresponding eigenvalue of $\\mathbf{C}$ will be $\\lambda_i + \\beta^{-1}$.\n",
        "It is therefore sufficient that the kernel matrrix $k(\\mathbf{x}_n, \\mathbf{x}_m)$ be positive semidefinite for any pair of points $\\mathbf{x}_n$ and $\\mathbf{x}_m$, so that $\\lambda_i \\geq 0$, because any eigenvalue $\\lambda_i$ that is zero will still give rise to a positive eigenvalue for $\\mathbf{C}$ because $\\beta \\ge 0$.\n",
        "\n",
        "Note that the mean (6.66) of the predictive distribution can be written, as a function of $\\mathbf{x}_{N+1}$, in the form  $$\\quad m(\\mathbf{x}_{N+1}) = \\sum_{n=1}^{N} a_n k(\\mathbf{x}_n \\mathbf{x}_{N+1})$$ where $a_n$ is the $\\text{n}^{\\text{th}}$ component of $\\mathbf{C}_N^{-1}\\mathbf{t}$. Thus, if the kernel $k(\\mathbf{x}_n, \\mathbf{x}_m)$ depends only on the distance $\\Vert \\mathbf{x}_n - \\mathbf{x}_m \\Vert$, then we obtain an expansion on radial basis functions.\n",
        "The results (6.66) and (6.67) define the predictive distribution for Gaussian process regression with an arbitrary kernel function $k(\\mathbf{x}_n, \\mathbf{x}_m)$.\n",
        "> Implement the predict function based on Eq. 6.68 and extend this idea for the confidence sigma. Don't forget to extend previous functions to include the noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f_lTJcXUc-5"
      },
      "source": [
        "class GaussianProcess(GaussianProcess):\n",
        "    def fit(self, X, y, noise=.1):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def predict_conditional(self, inp):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWybCi9vUc-5"
      },
      "source": [
        "> Plot the predictions of the Gaussian Process with the corresponding dataset. Plot the standard deviation as done [here](https://stackoverflow.com/questions/45136420/filling-range-of-graph-in-matplotlib)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgyaVKIiUc-6"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjsBbYRkUc-6"
      },
      "source": [
        "> Test your code with the following interactive plot and modify the parameters to be get an intuitive understanding for the behavior of the kernel.\n",
        "> You might have to adapt the code if it is not working out of the box with your own implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HqvN25lUc-7"
      },
      "source": [
        "def plot_predict_conditional(noise=.2, theta0=1, theta1=1, theta2=0, theta3=0):\n",
        "    kernel_func = ExponentialCovariance(theta0=theta0, theta1=theta1, theta2=theta2, theta3=theta3)\n",
        "    gp = GaussianProcess(kernel_func)\n",
        "    gp.fit(X, y, noise=noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(13, 5))\n",
        "    axis = np.linspace(min(X)-2, max(X)+2, 101)\n",
        "\n",
        "    preds = np.c_[[gp.predict_conditional(x) for x in axis]]\n",
        "    mean_pred = preds[:, 0].flatten()\n",
        "    var_pred = preds[:, 1].flatten()\n",
        "    plt.plot(axis, mean_pred)\n",
        "    plt.fill_between(axis, mean_pred - np.sqrt(var_pred), mean_pred + np.sqrt(var_pred), alpha=.3)\n",
        "    plt.scatter(X, y)\n",
        "\n",
        "interact(plot_predict_conditional,  noise=(0.01, 1, 0.01), theta0=(0, 5, .1), theta1=(0, 5, .1), theta2=(0, 5, .1), theta3=(0, 5, .1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}